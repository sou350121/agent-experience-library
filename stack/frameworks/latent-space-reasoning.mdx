# 隐空间推理：Coconut 与连续思维链 (Continuous CoT)

## 1. 背景：显式思维链的局限

目前的 Reasoning 模型（如 o1, DeepSeek R1）大多依赖**显式思维链 (Explicit CoT)**，即模型必须将思考过程通过文字 Token 一一写出来。

**局限性：**
- **效率低**：文字表达往往比纯粹的逻辑推理更冗长。
- **并非真实思考**：人类往往是先有答案，再补齐逻辑。
- **带宽受限**：受限于 Token 生成速度和上下文窗口。

## 2. 核心技术：Coconut (Chain of Continuous Thought)

田渊栋团队提出的 **Coconut** 方案，主张将推理过程从 Token 空间转移到 **连续隐空间 (Continuous Latent Space)**。

### 2.1 工作原理
- **隐向量思考**：Agent 不输出文字，而是输出一系列高维向量（Latent States）。
- **非线性跨越**：在向量空间中，一个步骤可能包含多步 Token 推理的信息。
- **按需解码**：只有当需要向人类展示或输出最终结论时，才将隐空间状态解码为文字。

### 2.2 核心优势
- **更高效率**：推理链长度显著缩短（研究表明隐空间推理与显式推理呈平方级效率差异）。
- **更强性能**：能够保留所有可能的搜索路径（Search Paths），而不是被迫在每一步都坍缩到具体的 Token。

## 3. 范式转变：思考未必用语言

田渊栋认为，未来的高效 Agent 推理将是**隐显结合**的：
- **深层推理（隐空间）**：用于复杂逻辑搜索、数学证明、代码架构设计。
- **表面沟通（显式 Token）**：用于人机交互、文档产出、最终交付。

## 4. 对 Agent 开发的启示

1. **关注内部表示**：未来评价 Agent 强弱的标准，将从“回答得好听”转变为“内部表示（Representation）的泛化能力”。
2. **推理时扩展 (Test-Time Scaling)**：隐空间推理为推理侧算力提供了更高效的利用路径，而不只是单纯增加 Token 采样。

---

**关联阅读：**
- [Jagged Intelligence 与 RLVR](../capabilities/jagged-intelligence-rlvr.mdx)
- [Scaling Law 之后的效率跃迁](../capabilities/ai-efficiency-leap.mdx)
