# 1X World Model: 具身智能的「想象力」范式

從「看一幀→出動作」的傳統 VLA，到「先想象成功視頻→再映射動作」的 **1X World Model (1XWM)**，具身智能正在迎來它的「思維鏈 (CoT)」時刻。

## 🧠 核心洞见
> **「脑子会了」是「手学会」的前提。**
> 1XWM 的核心價值在於：它讓機器人直接吃到了互聯網視頻預訓練的紅利。與其在昂貴的機器人數據中苦苦掙扎，不如先在海量視頻中學習「世界如何運轉」。

## 🛠 1XWM 的架構模型
1.  **世界模型主幹 (World Model Backbone)**：基於擴散模型的未來視頻生成，根據指令「想象」場景如何演化。
2.  **逆動力學模型 (IDM)**：將想象出的視頻幀變化，精準映射為機器人的關節動作。
3.  **拒絕採樣 (Rejection Sampling)**：並行生成多個「未來」，由 VLM 評估器挑選那個「看起來會成功」的路徑去執行。

## 🚀 實踐意義
- **數據效率**：先學通用物理動態，再用少量機器人數據對齊。
- **OOD 泛化**：通過互聯網視頻學會開門、掉落、移動等物理先驗。
- **容錯性**：推理時的並行「想象」提供了類似搜索的優化空間。

## 🔗 相關資源
- [1X 官方：World Model Self-Learning](https://www.1x.tech/discover/world-model-self-learning)
- [具身 AI 經濟學](./embodied-ai-economic-agents.mdx)
