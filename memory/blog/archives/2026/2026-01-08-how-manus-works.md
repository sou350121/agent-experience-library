# 第 3 篇 · Manus 的工作原理

恭喜 Manus 被 Meta 收购。这对 AI 行业从业者来说是一剂强心剂。Manus 目前被视为通用 Agent 的代表，但其实很多人还并不知道什么是 Agent，或者说，不了解 Agent 与非 Agent 之间的区别，我自己也困惑了很久。在今年 3 月 Manus 正式上线之前，整个行业对于 Agent 的使用确实很混乱，我经常问的一个问题：“ChatGPT 算不算 Agent？”，答案也不统一。可以说是，一千个创业者口中有一千种 Agent 含义了。但当下我们在 AI 相关的语境下提到 Agent 时，它的含义已经显著的收敛了，在这点上确实得感谢 Manus 。

Agent 的含义倒在其次，Agent 到底是怎么运行的？为什么好像 Agent 就比 ChatGPT 厉害呢？今天就借着 Manus 的例子，用非技术化的语言，解释一下“当我们使用 Agent 时，它内部发生了什么”这件事。

---

为了更好的理解，我们先说明一下 Agent 中最重要的 3 个“角色”，分别是：**用户、服务端、LLM**（大语言模型，下文简称模型）。

- **用户**：最好理解，就是提出问题、需求的角色。
- **模型**：是一个“你给我一些文本，我就会吐出来一些文本”的机器。它只能做这件事，但是在做这件事的时候它表现的还算智能，智力水平在快速提升。
- **服务端**：在用户和模型之间建立桥梁完成所有其余必要工作的，统称为服务端。它至少要处理：
    - 接受用户的信息
    - 提供给模型的输入
    - 接受模型的输出
    - 提供给用户的反馈信息

---

### 1️⃣ 从 Chatbot 到 Agent：9.11 和 9.8 谁大？

我们还是采用上一篇中的《9.11 和 9.8 谁大》的例子（如果你错过了，可以回看《第 2 篇 · 上下文工程就是把没明说的都明说出来》）。我们先假定模型的水平还是之前那种，不能直接正确回答小数的大小比较的问题。

#### 在 Chatbot 中发生的流程：
1. **用户输入**：{比较 9.11 和 9.8 的大小}
2. **服务端打包**：拼成一个新的给模型的输入，带上 system prompt。
3. **模型输出**：{ 因为 11 比 8 大，所以 9.11 比 9.8 大。}
4. **服务端返回**：用户收到了错误答案。

为了解决这个问题，以前我们需要优化 Prompt（提示词工程），但这样会导致每个问题都要带上一长串逻辑，非常冗余且浪费 Token。

#### 在 Agent 中发生的流程：
Agent 采用了新的流程（ReAct 循环）：

1. **用户输入**：{ 比较 9.11 和 9.8 的大小 }
2. **服务端给模型的输入**：
   ```text
   这是用户需求："比较 9.11 和 9.8 的大小"
   这是你可以使用的工具：
       list_file {列出全部文件列表}
       read_file {读取特定文件内容}
       write_file {在特定文件中写入内容}
       create_file {创建文件}
       回复用户特定内容
   请回复下一步的操作是什么？
   ```
3. **模型回复**：{ 执行 `list_file` 操作，列出全部文件列表 }
4. **服务端执行并再次输入**：
   ```text
   目前已存在的文件有：
       比较数值大小的方法.md
       ...
   请回复下一步的操作是什么？
   ```
5. **模型回复**：{ 执行 `read_file` 操作，读取 `比较数值大小的方法.md` }
6. **服务端读取内容并再次输入**：
   ```text
   文件内容：「比较两个数的大小的时候，首先要比较最高相同数位的数值的大小...」
   请回复下一步的操作是什么？
   ```
7. **模型回复（最终决策）**：
   ```text
   回复用户: 根据《 比较数值大小的方法.md 》中提供的方法，答案是：9.11 < 9.8
   ```

---

### 2️⃣ Agent 的核心设计思路

这就是 Agent 的核心：**定义好可以被使用的工具**。

至于每次要使用什么工具，我们就相信模型的判断。然后不停地把使用了工具之后的结果加进来，再去问模型。像个小孩子一样，不停地问，“然后呢？”，直到模型告诉你可以了，我们可以给用户结论了。

这个过程看似繁琐，但其实是个还挺精妙的设计：
- **接纳模型的不完美**：它不能一次性解决问题。
- **提供外部信息**：通过各种方式给模型提供它不知道的信息，充分利用模型的智力。

### 3️⃣ 给开发者（尤其是产品经理）的空间

这样的结构也给 Agent 开发者提供了发挥空间 —— 在模型能力不提升的情况下，也能有办法提高产品的效果。比如更好的工具定义、更垂直的知识库、更好的自动化流程等等。我前面描述的结构其实是个过于简陋的结构，事实上，在面对用户提出的诸如“分析特斯拉近期财报”等相对复杂问题时，模型都会先使用流程规划的工具，先创建个 ToDo.md 并写入内容，再基于这个文件不停追踪进展。

工程上的优化空间也非常大。可以想象，这种流程必然带来 Token 消耗的爆炸增长。如何有效控制成本就是一个大课题。以及记忆外部化、上下文卸载等等基于这个新结构新流程所衍生出来的技术方案，都为 Agent 开发打开了新思路。

当然，除了这个结构以外，模型本身的水平也至关重要，因为这里的判断和决策几乎都相信模型给的结果。在对工具的使用，尤其是长跨度任务规划中，Claude 3.5 Sonnet 的表现至关重要。Manus 和 Cursor 这些知名 Agent 产品都是这一波模型红利的受益者。但也不得不说，模型的能力在当时当下的时间点差不多就会到达这个水平，不是 Claude 也会是别人。

技术的洪流滚滚向前，任何人都无法阻挡，只能参与。

