# Agent 交互模型：角色、职责与闭环反馈

> **沉淀自：** [2026-01-08 Manus 的工作原理](../../blog/2026-01-08-how-manus-works.md)  
> **核心目标：** 理解 Agent 系统的物理构成与逻辑运行闭环，区分“纯模型聊天”与“智能体协作”。

---

## 1. 物理架构：三位一体的角色模型

一个完整的 Agent 系统由以下三个物理实体构成：

| 角色 | 核心职责 | 隐喻 | 局限性 |
| :--- | :--- | :--- | :--- |
| **用户 (User)** | 定义目标、提供约束、进行最终验收。 | 发令者 / 甲方 | 往往不具备完整的技术实现路径信息。 |
| **模型 (LLM)** | 逻辑推理、意图识别、决策规划、文本生成。 | 大脑 / 总工 | 只有“智力”，没有“手脚”；存在幻觉。 |
| **服务端 (Server)** | 工具执行、状态维护、上下文打包、反馈闭环。 | 桥梁 / 躯干 | 只有“执行力”，没有“智能”；完全听命于模型指令。 |

---

## 2. 逻辑逻辑：ReAct 闭环 (Reasoning + Acting)

Agent 之所以比普通 Chatbot 强大，在于它能通过 **Server** 调用工具，不断将“外部确定性信息”引入决策过程。

### 2.1 运行流程
1. **意图获取**：Server 接收 User 需求。
2. **决策规划 (Think)**：Server 将需求打包发给 LLM。LLM 判断当前信息不足，要求使用工具（如 `read_file`）。
3. **工具执行 (Act)**：Server 解析 LLM 指令，执行真实的物理动作（读取文件、运行命令）。
4. **结果反馈 (Observe)**：Server 将工具执行结果（内容、报错、状态）喂回给 LLM。
5. **循环迭代**：LLM 基于新信息重新决策。如果不满足退出条件，返回步骤 2。
6. **最终交付**：LLM 给出最终结论，Server 将其呈现给 User。

### 2.2 为什么 Agent 能对抗幻觉？
- **Chatbot** 模式：模型仅凭参数内的“记忆”回答，遇到模糊地带容易编造。
- **Agent** 模式：模型通过工具访问“外部真相”（如源代码、最新文档），将回答建立在可观察、可验证的证据之上。

---

## 3. 治理与优化空间

对于 Agent 开发者（或产品经理）而言，优化的核心在于：

1. **工具定义 (Tool Definitions)**：
   - 提供更原子化、更精准的工具。
   - 编写清晰的工具描述，引导模型在正确的时间调用正确的工具。

2. **知识工程 (Context/Knowledge)**：
   - 建立高质量的 RAG（检索增强生成）系统。
   - 通过 `@` 符号或预定义上下文，减少模型搜索的盲目性。

3. **流程确定性 (Idempotency Safety Wall)**：
   - 对于高风险动作（如删除代码），建立“提案-审核-执行”的治理机制。
   - 详见：[确定性治理：幂等安全墙](./ai-coding-agent-architecture.mdx)。

---

## 4. 总结

Agent 的精妙之处在于它**接纳了模型的不完美**。它不要求模型一次性给出完美答案，而是通过“多轮询问、外部取证、逐步逼近”的工程化方式，将模型的推理能力最大化地转化为生产力。

