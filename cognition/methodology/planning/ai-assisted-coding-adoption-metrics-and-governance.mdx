# AI 参与编码的检测、度量与治理：从“偷偷用”到“系统化基本功”

> 目标：把 AI Coding Agent 的渗透从“感觉/口号”变成**可观测、可治理、可复现**的工程事实。

---

## 1. 核心判断

- **AI 将从工具变成基本功**：未来的差距来自协作协议与治理能力。
- “检测到 AI 痕迹”不等于“AI 参与度的真实值”：可检测只是下界。

---

## 2. 你到底想度量什么？（先选指标，不要乱采集）

### 2.1 三类指标

- **Usage（使用）**：AI 参与了多少？
  - 例：AI 生成/修改的行数占比、AI 辅助 PR 占比
- **Quality（质量）**：AI 带来了什么？
  - 例：缺陷率、回滚率、review 修改轮数、线上事故
- **Economics（经济性）**：AI 是否真的省钱？
  - 例：从需求到交付的周期、返工率、token/算力成本

### 2.2 最小可行指标（MVP）
- [ ] 每周：AI 辅助 PR 占比
- [ ] 每周：PR 平均 review 轮次
- [ ] 每月：回滚/事故数

---

## 3. 检测：哪些是“可检测痕迹”，哪些是“不可见协作”

### 3.1 可检测（通常是下界）
- 代码注释/提交信息里的模型标记
- 统一的生成模板（风格一致、结构一致、重复片段）
- 仓库内显式的 agent 规则文件与提示词资产

### 3.2 不可见（更接近真实世界）
- 开发者在本地用 Agent 提议方案，但最终手动敲代码
- 通过对话得到 debug 思路，但代码由人类实现

结论：
- 把“检测 AI 痕迹”当作**趋势信号**，不要当作精确度量。

---

## 4. 治理：把 AI 参与变成“可审计的协作协议”

### 4.1 最小护栏
- [ ] PR 必须写清楚：改动目的、风险、验证方式
- [ ] 高风险改动必须要求证据：复现步骤/日志/截图/基准对比
- [ ] 禁止把密钥写入 prompt 或代码

### 4.2 证据链（推荐做法）
把生成过程入库：
- `stories/`：需求单元
- `prompts/`：最终生效提示词
- `sessions/`：过程记录与失败路径

参考：
- `./hybrid-docops-agentops-best-practices.mdx`

---

## 5. 组织落地：两阶段迁移

### 5.1 阶段 A：允许使用，但必须可追溯
- 目标：不压制生产力，但要避免黑盒
- 措施：PR 模板 + 证据链

### 5.2 阶段 B：开始系统化（路由、技能、回归）
- 目标：从“会用”升级为“可治理”
- 措施：
  - Skill/Script（幂等安全墙）
  - 评测回归（换模型/策略必须回归）
  - 语义路由（多模型并存时降低成本与风险）

---

## 6. 一页清单（给 Tech Lead）

- [ ] 定义 MVP 指标（Usage/Quality/Economics 各一个）
- [ ] 建立 PR 证据链规范（可审计）
- [ ] 把高风险动作收口到幂等脚本（可回放/可回滚）
- [ ] 建立回归评测（真实任务集）
- [ ] 每月复盘：AI 带来了哪些失败模式？（写进 runbook）
